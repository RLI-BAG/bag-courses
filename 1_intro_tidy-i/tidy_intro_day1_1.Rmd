---
title: "Tidyverse Intro I"
author: ["Antoine & Nicolas", "cynkra GmbH"]
date: "January 25, 2022"
output:
  cynkradown::cynkra_slides:
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    seal: true
fontsize: 10pt
lang: english
font: frutiger
wide: false
colorlinks: false
logo: true
header-includes:
  - \usepackage{parskip}
---

<style type="text/css">
.remark-code {
    font-size: 12px;
}
.font17 {
    font-size: 17px;
}
.font14 {
    font-size: 14px;
}
</style>

<!-- TODO general remarks:
  - bullet points start with a mix of upper/lower case; aim for some consistency
  - some times you use contractions; for consistency, I'd try to avoid this in
    bullet points: i.e. write do not instead of don't
  - sometimes you add a space before ":" or "!"; for consistency, don't
  - some titles start with lower case letters, for consistency, always start
    with uppercase; also you mix title case with regular case in titles, choose
    one
  - fyi, there was already some material on reading available, e.g.
    https://krlmlr.github.io/vistransrep/import.html
    https://krlmlr.github.io/vistransrep/2019-04-zhr/import.html
    or for more in-depth on readr
    https://r4ds.had.co.nz/data-import.html
    it's fine if you want to add your own stuff, i'm just pointing this out to
    you in case you had missed this
  - content-wise, i think it's good. maybe add something on rio? kirill used
    this in his material, might be useful if you have an excel workbook or so..
  - do you want to always do exercises in-line? initially i though we might
    have exercises in separate files and we distribute an archive containing
    also some dataset etc.
-->

# Tidyverse Intro I-1

* Instructor introduction
* Introducing the tidyverse
* Packages of the tidyverse
* Getting help
* Exploring data
* Read and write the data

---
# Cynkra + Instructor intro

* Cynkra
* Antoine Fabri
* Nicolas Benett

---

# Introducing the tidyverse


Collection of data science tools

--

* Import/export

* Transform
   * clean up
   * reshape to tidy form
   * process
   
* Visualize



???
The goal of this course is to introduce the tidyverse, a collection of data
science tools within R for transforming and visualizing data.

---

# Other tools

* Base R
* {data.table}
* ...

--

Tidyverse strong points :

* Readable code
* Very wide range of features
* Documentation convenient to navigate
* Professional maintainers
* RStudio integration


???
There are other data manipulation tools in R, and we cannot do everything with
the tidyverse. {data.table} is a common and excellent alternative, that favors
compact code, execution speed and low dependencies. We can also do a lot with
base R. Nevertheless in our sense the tidyverse provides the most intuitive and
versatile framework out there.

These tools are maintained by RStudio, the company that designed the user
interface of the same name, that you use to program in the R language, this means
there is a solid team and budget behind it and that that they are very attentive
to bug reports and new features that might help users.

---

# the {tidyverse} package

Tidyverse is meta-package!

* Does not contain much functionality
* Loads a set of packages: the "core" tidyverse packages

```{r, eval}
# install.packages("tidyverse")
library(tidyverse)
```

???

tidyverse is a meta package, when you attach it, using `library(tidyverse)`,
you attach several packages, these packages each have their specificity and are
sometimes useful in isolation but they're designed to work together, using
harmonized convention, so for the purpose of data analysis it's often very
convenient to be able to type `library(tidyverse)` and have (almost) all the tools we need.

<!-- TODO maybe introduce conflicted here? -->

---

# Core tidyverse packages

No need to memorize them! But it's good to recognize the names

* **readr**: to read or write rectangular data
* **dplyr**: to manipulate tidy data.
* **tidyr**: to tidy the data
* **tibble**: to improve the native data frame
* **purrr**: to work with functions and vectors.
* **stringr**: to work with strings
* **forcats**: to work with factors
* **ggplot2**: to create graphics

???
 You don't need to remember which function comes from which package!
 you can always print the function if you need to know!

---

# Auxiliary tidyverse packages ?

There is (much) more! 

Auxiliary (helper) packages:

* not loaded by `library(tidverse)`
* same group of maintainer, same philosophy, same conventions

short list :

* lubridate
* readxl
* glue


???

Technically, the above are the "core" tidyverse packages, there is more!
Other RStudio packages form the extended tidyverse but are not attached by
`library(tidyverse)`, some interesting ones are lubridate, readxl and glue.

---

# Getting help
 
* don't remember everything!
* practice forgetting and recovering info

* Doc is usually good : `?some_function`
* http:://www.tidyverse.org -> links to package sites
  * Introduction to package's main functions
  * function reference shows help pages by category
  * Vignettes illustrate use cases
* Rstudio commmunity : https://community.rstudio.com
* twitter : #rstats
* StackOverflow : http://www.stackoverflow.com

???
You're not supposed to remember everything! You really don't need to remember
 much in fact, but you need to know the path to the information.
 `?` works pretty well! running the examples help
 tidyverse website, package websites with vignettes and reference
 humans !
 * rstudio forum have volunteers and staff help you with any R question, and won't ever make you
 feel bad about a "silly" question, especially if it's about their packages!
 * twitter : the R community is really positive and you might get a great answer really fast #rstats
 * stackoverflow : the ultimate Q&A site if you have a more complex question, look
 if it has been asked, take the time to formulate it well and you'll be answers very fast!

---

# Explore data

```{r, eval = TRUE}
# install.packages("pixarfilms")
library(pixarfilms)
```

Contains 5 datasets, we'll use 2:

* pixar_films
* public_response

---

# Explore data

Exercise!

Look at the `pixar_films` dataset

* print it
* use `glimpse()`
* install {skimr} and use `skim()` on the data

What is the advantage of each of those ?

???
For exercises and examples we'll use toy data set about pixar films provided by
the package pixarfilms, it contain 5 tables, take a couple minutes tom explore
them and tell us what data types you find there. Simply printing a dataset
is a fair way of getting aquainted with the data, glimpse() is sometimes 
a useful alternative, `{skimr}` is not a tidyverse package but it's too good
to ignore!

---
layout: true
class: .font14

# Explore data

---

```{r}
pixar_films
```

---


```{r}
# from {tibble} package, loaded by {tidyverse}
glimpse(pixar_films)
```

---

```{r, eval=FALSE}
# from {skimr} package, not a tidyverse package!
library(skimr)
skim(pixar_films)
```

```{r, echo=FALSE}
# from {skimr} package, not a tidyverse package!
library(skimr)
cat(capture.output(skim(pixar_films)), sep = "\n")
```

---
layout: false

# Write data

What do you think those do ?

 * `readr::write_csv(x, file)`
 * `readr::write_tsv(x, file)`
 * `readr::write_delim(x, file, delim)`
 * `writexl::write_excel(x, path)`
 * `writexl::write_excel(x, path)`

--

Exercise!

 * Save pixar_films to a csv file
 * Save the whole set of 5 tables to an xlsx file
 * Open these files and look at the result
 * Where are the data types ?
 
???
 Usually we start analysis by getting data from somewhere, this data might come
 directly from a database but very often it will come from files, and these
 files will often be .csv or excel file. Here we'll do it in reverse and we'll
 write the files first and learn to read them back. readr (already loaded with tidyverse),
 readxl and writexl are the packages we'll need.
 
---

# Write data 

```{r}
readr::write_csv(x = pixar_films, file = "pixar_films.csv")
writexl::write_xlsx(x = list(pixar_films = pixar_films), path = "pixar_films.xlsx")
```

```{r, eval = FALSE}
# bonus tricks to open files from R!
file.edit("pixar_films.csv")
browseURL("pixar_films.xlsx")
```

.pull-left[
```
number,film,release_date,run_time,film_rating
1,Toy Story,1995-11-22,81,G
2,A Bug's Life,1998-11-25,95,G
3,Toy Story 2,1999-11-24,92,G
4,"Monsters, Inc.",2001-11-02,92,G
5,Finding Nemo,2003-05-30,100,G
...
```
]

.pull-right[
<img src="excel.png" alt=""/>
]
 
---
layout: true
class: .font14

# Read data

---

What do you think those do ?

* `readr::read_csv(file)`
* `readr::read_tsv(file)`
* `readxl::read_excel(path, sheet)`
 
--

Exercise!

* Read back csv and xlsx datasets we saved
  * `pixar_films_from_csv`
  * `pixar_films_from_xlsx`
* Look at the output displayed by `readr::read_csv()`
* Look at the data types
* Did we reproduce the original ?

---

```{r}
pixar_films_from_csv <- readr::read_csv("pixar_films.csv")
pixar_films_from_xlsx <- readxl::read_excel("pixar_films.xlsx", "pixar_films")
pixar_films_from_csv
pixar_films_from_xlsx
```

<!-- TODO too much output -->

---

```{r}
waldo::compare(
  pixar_films,
  pixar_films_from_csv
)
```

???
the "number" column, which was stored as a character, was imported as numeric
the function checks the first 1000 rows and try to make the best guess, usually it's
good enough!

---

```{r}
waldo::compare(
  pixar_films,
  pixar_films_from_xlsx
)
```

???
Excel recognized the char col and the date, but we got back a date-time object
rather than a date!

---

```{r}
pixar_films_from_csv <- readr::read_csv("pixar_films.csv")

spec(pixar_films_from_csv)

pixar_films_from_csv <- readr::read_csv("pixar_films.csv", col_types = cols(
  number = col_character(), # we changed to keep it as character
  film = col_character(),
  release_date = col_date(format = ""),
  run_time = col_double(),
  film_rating = col_character()
))
```

<!-- TODO too much output -->


???
As we see types have been guessed.
 Were they guessed right ? This output is helpful the first time,
 but we don't want to clutter the output of our scripts! Try to make the message
 quieter using the given recommendations.

---
layout: false

# Reading and writing correctly is important!

* good reading
  * no data loss
  * no awkward transformation to fix what wasn't broken!
* good writing
  * no spoiling your good work
  * easy good reading!
  * less opportunity for error by collaborators down the line
  
???
good writing is straightforward if we use the functions above, issues often come from other
systems. good reading is harder.
90% of weird transformations you need to fix data you just read are possible
through the reading function, skip rows, take only a selection of column or a range,
consider this value as missing... take the time to read the doc in those cases.
